"""
MetaLife OS - Google AI Studio (Gemini) Provider
Google Gemini APIë¥¼ ì‚¬ìš©í•œ LLM ì œê³µì êµ¬í˜„
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class BaseProvider(ABC):
    """LLM ì œê³µì ê¸°ë³¸ í´ë˜ìŠ¤"""

    @abstractmethod
    async def generate(self, prompt: str, **kwargs) -> str:
        pass

    @abstractmethod
    async def generate_with_tools(
        self, prompt: str, tools: List[Dict]
    ) -> Tuple[str, List[Dict]]:
        pass

    @abstractmethod
    def get_model_info(self) -> Dict[str, Any]:
        pass


class GeminiProvider(BaseProvider):
    """
    Google AI Studio (Gemini) ì œê³µì
    
    ì‚¬ìš©ë²•:
        provider = GeminiProvider(api_key="your-api-key")
        response = await provider.generate("ì•ˆë…•í•˜ì„¸ìš”")
    """

    def __init__(
        self,
        api_key: str,
        model: str = "gemini-2.0-flash-exp",
        temperature: float = 0.7,
        max_tokens: int = 8192,
    ):
        self.api_key = api_key
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self._client = None
        self._initialized = False

    def _init_client(self):
        """Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        if self._initialized:
            return

        try:
            import google.generativeai as genai

            genai.configure(api_key=self.api_key)
            self._client = genai.GenerativeModel(
                model_name=self.model,
                generation_config={
                    "temperature": self.temperature,
                    "max_output_tokens": self.max_tokens,
                    "top_p": 0.95,
                    "top_k": 40,
                },
            )
            self._initialized = True
            logger.info(f"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.model}")
        except ImportError:
            raise ImportError(
                "google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "'pip install google-generativeai' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”."
            )
        except Exception as e:
            logger.error(f"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def generate(self, prompt: str, **kwargs) -> str:
        """
        Gemini APIë¡œ í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            prompt: ìƒì„±í•  í”„ë¡¬í”„íŠ¸
            **kwargs: ì¶”ê°€ ì˜µì…˜ (system_instruction ë“±)
        
        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        self._init_client()

        try:
            # ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ ì²˜ë¦¬
            system_instruction = kwargs.get("system_instruction", "")
            if system_instruction:
                full_prompt = f"{system_instruction}\n\n{prompt}"
            else:
                full_prompt = prompt

            logger.info(f"Gemini ìƒì„± ìš”ì²­: {len(full_prompt)} ë¬¸ì")

            # ë™ê¸° í˜¸ì¶œì„ ë¹„ë™ê¸°ë¡œ ë˜í•‘
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, lambda: self._client.generate_content(full_prompt)
            )

            result = response.text
            logger.info(f"Gemini ì‘ë‹µ ìˆ˜ì‹ : {len(result)} ë¬¸ì")
            return result

        except Exception as e:
            logger.error(f"Gemini ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    async def generate_with_tools(
        self, prompt: str, tools: List[Dict]
    ) -> Tuple[str, List[Dict]]:
        """
        ë„êµ¬ í˜¸ì¶œê³¼ í•¨ê»˜ í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡
        
        Returns:
            (ìƒì„±ëœ í…ìŠ¤íŠ¸, ë„êµ¬ í˜¸ì¶œ ëª©ë¡) íŠœí”Œ
        """
        self._init_client()

        try:
            # ë„êµ¬ ìŠ¤í‚¤ë§ˆë¥¼ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            gemini_tools = self._convert_tools_to_gemini_format(tools)

            # ë„êµ¬ì™€ í•¨ê»˜ ìƒì„± (í˜„ì¬ëŠ” ê¸°ë³¸ ìƒì„±ìœ¼ë¡œ ëŒ€ì²´)
            # Geminiì˜ function callingì€ ë³„ë„ êµ¬í˜„ í•„ìš”
            response = await self.generate(prompt)
            
            # TODO: ì‹¤ì œ ë„êµ¬ í˜¸ì¶œ íŒŒì‹± êµ¬í˜„
            tool_calls = []

            return response, tool_calls

        except Exception as e:
            logger.error(f"Gemini ë„êµ¬ í˜¸ì¶œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def _convert_tools_to_gemini_format(self, tools: List[Dict]) -> List[Dict]:
        """OpenAI í˜•ì‹ ë„êµ¬ë¥¼ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        gemini_tools = []
        for tool in tools:
            if tool.get("type") == "function":
                func = tool.get("function", {})
                gemini_tools.append({
                    "name": func.get("name"),
                    "description": func.get("description"),
                    "parameters": func.get("parameters", {}),
                })
        return gemini_tools

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "provider": "google",
            "model": self.model,
            "capabilities": ["text", "code", "vision", "tools"],
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
        }

    async def generate_chat(
        self, messages: List[Dict[str, str]], **kwargs
    ) -> str:
        """
        ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ìƒì„±
        
        Args:
            messages: [{"role": "user/assistant", "content": "..."}] í˜•ì‹
        
        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        self._init_client()

        try:
            # ë©”ì‹œì§€ë¥¼ Gemini ì±„íŒ… í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            chat = self._client.start_chat(history=[])
            
            # ì´ì „ ë©”ì‹œì§€ ì²˜ë¦¬
            for msg in messages[:-1]:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "user":
                    chat.send_message(content)
            
            # ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¡œ ì‘ë‹µ ìƒì„±
            last_message = messages[-1].get("content", "")
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, lambda: chat.send_message(last_message)
            )

            return response.text

        except Exception as e:
            logger.error(f"Gemini ì±„íŒ… ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    async def count_tokens(self, text: str) -> int:
        """í† í° ìˆ˜ ê³„ì‚°"""
        self._init_client()

        try:
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None, lambda: self._client.count_tokens(text)
            )
            return result.total_tokens
        except Exception as e:
            logger.error(f"í† í° ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ëŒ€ëµì ì¸ ì¶”ì • (í•œê¸€ ê¸°ì¤€)
            return len(text) // 2


# í¸ì˜ í•¨ìˆ˜
def create_gemini_provider(
    api_key: Optional[str] = None,
    model: str = "gemini-2.0-flash-exp",
) -> GeminiProvider:
    """
    Gemini Provider ìƒì„± í—¬í¼ í•¨ìˆ˜
    
    Args:
        api_key: Google API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        model: ì‚¬ìš©í•  ëª¨ë¸ëª…
    
    Returns:
        GeminiProvider ì¸ìŠ¤í„´ìŠ¤
    """
    import os

    if api_key is None:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError(
                "GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "Google AI Studioì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”."
            )

    return GeminiProvider(api_key=api_key, model=model)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    import os

    async def test():
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âŒ GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
            return

        provider = GeminiProvider(api_key=api_key)
        
        print("ğŸ§ª Gemini Provider í…ŒìŠ¤íŠ¸")
        print("-" * 40)
        
        response = await provider.generate("ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨íˆ ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš”.")
        print(f"âœ… ì‘ë‹µ: {response[:200]}...")
        
        info = provider.get_model_info()
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´: {info}")

    asyncio.run(test())
